{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ０～９までの数字の画像からどの数字なのかを推論する畳み込みニューラルネットワーク（CNN）モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\deep-learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"ylecun/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    image = ds['train'][i]['image']\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f\"Label: {ds['train'][i]['label']}\")\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       " 'label': 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像サイズ (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(f\"画像サイズ {image.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込みニューラルネットワークのモデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 損失関数とオプティマイザーを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(type='torch', columns=['image', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルを訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 6.296\n",
      "[1, 200] loss: 6.639\n",
      "[1, 300] loss: 6.544\n",
      "[1, 400] loss: 6.754\n",
      "[1, 500] loss: 6.265\n",
      "[1, 600] loss: 6.239\n",
      "[1, 700] loss: 6.433\n",
      "[1, 800] loss: 6.399\n",
      "[1, 900] loss: 6.137\n",
      "[1, 1000] loss: 6.420\n",
      "[1, 1100] loss: 6.804\n",
      "[1, 1200] loss: 6.365\n",
      "[1, 1300] loss: 6.234\n",
      "[1, 1400] loss: 6.048\n",
      "[1, 1500] loss: 6.286\n",
      "[1, 1600] loss: 6.714\n",
      "[1, 1700] loss: 6.167\n",
      "[1, 1800] loss: 6.193\n",
      "[1, 1900] loss: 6.639\n",
      "[1, 2000] loss: 6.149\n",
      "[1, 2100] loss: 6.379\n",
      "[1, 2200] loss: 6.472\n",
      "[1, 2300] loss: 6.157\n",
      "[1, 2400] loss: 6.218\n",
      "[1, 2500] loss: 6.091\n",
      "[1, 2600] loss: 6.294\n",
      "[1, 2700] loss: 6.322\n",
      "[1, 2800] loss: 6.385\n",
      "[1, 2900] loss: 6.091\n",
      "[1, 3000] loss: 6.284\n",
      "[1, 3100] loss: 6.606\n",
      "[1, 3200] loss: 6.180\n",
      "[1, 3300] loss: 6.225\n",
      "[1, 3400] loss: 6.173\n",
      "[1, 3500] loss: 6.454\n",
      "[1, 3600] loss: 6.301\n",
      "[1, 3700] loss: 6.645\n",
      "[1, 3800] loss: 6.683\n",
      "[1, 3900] loss: 6.432\n",
      "[1, 4000] loss: 6.404\n",
      "[1, 4100] loss: 6.360\n",
      "[1, 4200] loss: 6.215\n",
      "[1, 4300] loss: 6.576\n",
      "[1, 4400] loss: 6.354\n",
      "[1, 4500] loss: 6.215\n",
      "[1, 4600] loss: 6.337\n",
      "[1, 4700] loss: 6.264\n",
      "[1, 4800] loss: 6.294\n",
      "[1, 4900] loss: 6.595\n",
      "[1, 5000] loss: 6.078\n",
      "[1, 5100] loss: 6.214\n",
      "[1, 5200] loss: 5.948\n",
      "[1, 5300] loss: 6.276\n",
      "[1, 5400] loss: 6.391\n",
      "[1, 5500] loss: 6.207\n",
      "[1, 5600] loss: 6.232\n",
      "[1, 5700] loss: 6.261\n",
      "[1, 5800] loss: 6.428\n",
      "[1, 5900] loss: 6.318\n",
      "[1, 6000] loss: 6.314\n",
      "[1, 6100] loss: 6.056\n",
      "[1, 6200] loss: 6.539\n",
      "[1, 6300] loss: 6.330\n",
      "[1, 6400] loss: 6.391\n",
      "[1, 6500] loss: 6.368\n",
      "[1, 6600] loss: 6.621\n",
      "[1, 6700] loss: 6.170\n",
      "[1, 6800] loss: 6.537\n",
      "[1, 6900] loss: 6.146\n",
      "[1, 7000] loss: 6.192\n",
      "[1, 7100] loss: 6.478\n",
      "[1, 7200] loss: 5.988\n",
      "[1, 7300] loss: 6.074\n",
      "[1, 7400] loss: 6.003\n",
      "[1, 7500] loss: 6.699\n",
      "[1, 7600] loss: 6.690\n",
      "[1, 7700] loss: 6.198\n",
      "[1, 7800] loss: 6.275\n",
      "[1, 7900] loss: 6.126\n",
      "[1, 8000] loss: 6.417\n",
      "[1, 8100] loss: 6.254\n",
      "[1, 8200] loss: 6.341\n",
      "[1, 8300] loss: 6.379\n",
      "[1, 8400] loss: 6.424\n",
      "[1, 8500] loss: 6.586\n",
      "[1, 8600] loss: 6.002\n",
      "[1, 8700] loss: 6.169\n",
      "[1, 8800] loss: 5.993\n",
      "[1, 8900] loss: 6.474\n",
      "[1, 9000] loss: 6.274\n",
      "[1, 9100] loss: 6.617\n",
      "[1, 9200] loss: 5.949\n",
      "[1, 9300] loss: 6.415\n",
      "[1, 9400] loss: 6.245\n",
      "[1, 9500] loss: 6.360\n",
      "[1, 9600] loss: 6.278\n",
      "[1, 9700] loss: 6.227\n",
      "[1, 9800] loss: 6.424\n",
      "[1, 9900] loss: 6.128\n",
      "[1, 10000] loss: 6.407\n",
      "[1, 10100] loss: 6.512\n",
      "[1, 10200] loss: 6.476\n",
      "[1, 10300] loss: 6.457\n",
      "[1, 10400] loss: 6.204\n",
      "[1, 10500] loss: 6.308\n",
      "[1, 10600] loss: 6.585\n",
      "[1, 10700] loss: 6.407\n",
      "[1, 10800] loss: 5.927\n",
      "[1, 10900] loss: 6.322\n",
      "[1, 11000] loss: 6.171\n",
      "[1, 11100] loss: 6.510\n",
      "[1, 11200] loss: 6.116\n",
      "[1, 11300] loss: 6.548\n",
      "[1, 11400] loss: 6.026\n",
      "[1, 11500] loss: 6.281\n",
      "[1, 11600] loss: 6.014\n",
      "[1, 11700] loss: 6.291\n",
      "[1, 11800] loss: 6.664\n",
      "[1, 11900] loss: 6.727\n",
      "[1, 12000] loss: 5.894\n",
      "[1, 12100] loss: 6.220\n",
      "[1, 12200] loss: 6.165\n",
      "[1, 12300] loss: 6.345\n",
      "[1, 12400] loss: 5.867\n",
      "[1, 12500] loss: 6.168\n",
      "[1, 12600] loss: 6.418\n",
      "[1, 12700] loss: 6.769\n",
      "[1, 12800] loss: 6.313\n",
      "[1, 12900] loss: 6.322\n",
      "[1, 13000] loss: 6.479\n",
      "[1, 13100] loss: 6.203\n",
      "[1, 13200] loss: 6.360\n",
      "[1, 13300] loss: 6.723\n",
      "[1, 13400] loss: 6.834\n",
      "[1, 13500] loss: 6.607\n",
      "[1, 13600] loss: 6.157\n",
      "[1, 13700] loss: 6.316\n",
      "[1, 13800] loss: 6.310\n",
      "[1, 13900] loss: 6.218\n",
      "[1, 14000] loss: 6.216\n",
      "[1, 14100] loss: 6.446\n",
      "[1, 14200] loss: 6.337\n",
      "[1, 14300] loss: 6.407\n",
      "[1, 14400] loss: 6.550\n",
      "[1, 14500] loss: 6.153\n",
      "[1, 14600] loss: 5.989\n",
      "[1, 14700] loss: 6.260\n",
      "[1, 14800] loss: 6.332\n",
      "[1, 14900] loss: 6.199\n",
      "[1, 15000] loss: 6.549\n",
      "[2, 100] loss: 6.617\n",
      "[2, 200] loss: 6.771\n",
      "[2, 300] loss: 6.792\n",
      "[2, 400] loss: 6.454\n",
      "[2, 500] loss: 6.337\n",
      "[2, 600] loss: 6.253\n",
      "[2, 700] loss: 6.194\n",
      "[2, 800] loss: 6.196\n",
      "[2, 900] loss: 6.370\n",
      "[2, 1000] loss: 6.333\n",
      "[2, 1100] loss: 6.260\n",
      "[2, 1200] loss: 6.693\n",
      "[2, 1300] loss: 6.087\n",
      "[2, 1400] loss: 6.291\n",
      "[2, 1500] loss: 6.148\n",
      "[2, 1600] loss: 6.556\n",
      "[2, 1700] loss: 5.840\n",
      "[2, 1800] loss: 6.347\n",
      "[2, 1900] loss: 6.518\n",
      "[2, 2000] loss: 6.370\n",
      "[2, 2100] loss: 6.348\n",
      "[2, 2200] loss: 6.357\n",
      "[2, 2300] loss: 6.181\n",
      "[2, 2400] loss: 6.297\n",
      "[2, 2500] loss: 6.389\n",
      "[2, 2600] loss: 6.846\n",
      "[2, 2700] loss: 6.470\n",
      "[2, 2800] loss: 6.801\n",
      "[2, 2900] loss: 6.149\n",
      "[2, 3000] loss: 6.316\n",
      "[2, 3100] loss: 6.525\n",
      "[2, 3200] loss: 6.289\n",
      "[2, 3300] loss: 6.746\n",
      "[2, 3400] loss: 6.343\n",
      "[2, 3500] loss: 6.308\n",
      "[2, 3600] loss: 6.133\n",
      "[2, 3700] loss: 6.292\n",
      "[2, 3800] loss: 6.183\n",
      "[2, 3900] loss: 6.273\n",
      "[2, 4000] loss: 6.058\n",
      "[2, 4100] loss: 6.308\n",
      "[2, 4200] loss: 6.388\n",
      "[2, 4300] loss: 5.971\n",
      "[2, 4400] loss: 5.966\n",
      "[2, 4500] loss: 6.415\n",
      "[2, 4600] loss: 6.094\n",
      "[2, 4700] loss: 6.070\n",
      "[2, 4800] loss: 6.452\n",
      "[2, 4900] loss: 6.428\n",
      "[2, 5000] loss: 6.370\n",
      "[2, 5100] loss: 6.134\n",
      "[2, 5200] loss: 6.289\n",
      "[2, 5300] loss: 6.070\n",
      "[2, 5400] loss: 6.222\n",
      "[2, 5500] loss: 6.627\n",
      "[2, 5600] loss: 6.235\n",
      "[2, 5700] loss: 6.163\n",
      "[2, 5800] loss: 6.497\n",
      "[2, 5900] loss: 6.739\n",
      "[2, 6000] loss: 6.456\n",
      "[2, 6100] loss: 5.848\n",
      "[2, 6200] loss: 6.745\n",
      "[2, 6300] loss: 6.582\n",
      "[2, 6400] loss: 6.685\n",
      "[2, 6500] loss: 5.884\n",
      "[2, 6600] loss: 6.278\n",
      "[2, 6700] loss: 6.239\n",
      "[2, 6800] loss: 6.167\n",
      "[2, 6900] loss: 6.299\n",
      "[2, 7000] loss: 6.235\n",
      "[2, 7100] loss: 6.180\n",
      "[2, 7200] loss: 6.402\n",
      "[2, 7300] loss: 6.144\n",
      "[2, 7400] loss: 6.484\n",
      "[2, 7500] loss: 6.164\n",
      "[2, 7600] loss: 6.299\n",
      "[2, 7700] loss: 6.246\n",
      "[2, 7800] loss: 6.250\n",
      "[2, 7900] loss: 6.084\n",
      "[2, 8000] loss: 6.418\n",
      "[2, 8100] loss: 6.391\n",
      "[2, 8200] loss: 6.232\n",
      "[2, 8300] loss: 6.440\n",
      "[2, 8400] loss: 6.359\n",
      "[2, 8500] loss: 6.370\n",
      "[2, 8600] loss: 6.211\n",
      "[2, 8700] loss: 6.169\n",
      "[2, 8800] loss: 6.190\n",
      "[2, 8900] loss: 6.004\n",
      "[2, 9000] loss: 6.339\n",
      "[2, 9100] loss: 6.232\n",
      "[2, 9200] loss: 6.755\n",
      "[2, 9300] loss: 6.343\n",
      "[2, 9400] loss: 6.352\n",
      "[2, 9500] loss: 6.337\n",
      "[2, 9600] loss: 6.582\n",
      "[2, 9700] loss: 6.049\n",
      "[2, 9800] loss: 6.376\n",
      "[2, 9900] loss: 6.114\n",
      "[2, 10000] loss: 6.226\n",
      "[2, 10100] loss: 6.599\n",
      "[2, 10200] loss: 6.483\n",
      "[2, 10300] loss: 6.256\n",
      "[2, 10400] loss: 6.302\n",
      "[2, 10500] loss: 6.081\n",
      "[2, 10600] loss: 6.484\n",
      "[2, 10700] loss: 6.232\n",
      "[2, 10800] loss: 6.667\n",
      "[2, 10900] loss: 6.510\n",
      "[2, 11000] loss: 5.940\n",
      "[2, 11100] loss: 6.223\n",
      "[2, 11200] loss: 6.719\n",
      "[2, 11300] loss: 6.251\n",
      "[2, 11400] loss: 5.868\n",
      "[2, 11500] loss: 6.268\n",
      "[2, 11600] loss: 5.996\n",
      "[2, 11700] loss: 6.332\n",
      "[2, 11800] loss: 6.181\n",
      "[2, 11900] loss: 6.279\n",
      "[2, 12000] loss: 6.309\n",
      "[2, 12100] loss: 6.298\n",
      "[2, 12200] loss: 6.389\n",
      "[2, 12300] loss: 6.480\n",
      "[2, 12400] loss: 6.818\n",
      "[2, 12500] loss: 6.633\n",
      "[2, 12600] loss: 6.268\n",
      "[2, 12700] loss: 6.300\n",
      "[2, 12800] loss: 6.394\n",
      "[2, 12900] loss: 6.082\n",
      "[2, 13000] loss: 6.420\n",
      "[2, 13100] loss: 6.542\n",
      "[2, 13200] loss: 6.208\n",
      "[2, 13300] loss: 6.650\n",
      "[2, 13400] loss: 6.154\n",
      "[2, 13500] loss: 6.615\n",
      "[2, 13600] loss: 6.546\n",
      "[2, 13700] loss: 6.226\n",
      "[2, 13800] loss: 6.153\n",
      "[2, 13900] loss: 6.211\n",
      "[2, 14000] loss: 6.316\n",
      "[2, 14100] loss: 6.252\n",
      "[2, 14200] loss: 6.299\n",
      "[2, 14300] loss: 6.178\n",
      "[2, 14400] loss: 6.008\n",
      "[2, 14500] loss: 6.557\n",
      "[2, 14600] loss: 6.335\n",
      "[2, 14700] loss: 6.380\n",
      "[2, 14800] loss: 6.148\n",
      "[2, 14900] loss: 6.964\n",
      "[2, 15000] loss: 6.173\n",
      "[3, 100] loss: 6.084\n",
      "[3, 200] loss: 6.164\n",
      "[3, 300] loss: 6.627\n",
      "[3, 400] loss: 6.512\n",
      "[3, 500] loss: 6.613\n",
      "[3, 600] loss: 6.039\n",
      "[3, 700] loss: 6.342\n",
      "[3, 800] loss: 6.048\n",
      "[3, 900] loss: 6.447\n",
      "[3, 1000] loss: 6.548\n",
      "[3, 1100] loss: 6.220\n",
      "[3, 1200] loss: 6.428\n",
      "[3, 1300] loss: 6.213\n",
      "[3, 1400] loss: 6.589\n",
      "[3, 1500] loss: 6.252\n",
      "[3, 1600] loss: 6.146\n",
      "[3, 1700] loss: 6.013\n",
      "[3, 1800] loss: 6.492\n",
      "[3, 1900] loss: 6.329\n",
      "[3, 2000] loss: 6.100\n",
      "[3, 2100] loss: 6.282\n",
      "[3, 2200] loss: 6.738\n",
      "[3, 2300] loss: 6.265\n",
      "[3, 2400] loss: 6.186\n",
      "[3, 2500] loss: 6.167\n",
      "[3, 2600] loss: 6.311\n",
      "[3, 2700] loss: 6.323\n",
      "[3, 2800] loss: 6.152\n",
      "[3, 2900] loss: 6.449\n",
      "[3, 3000] loss: 6.160\n",
      "[3, 3100] loss: 6.155\n",
      "[3, 3200] loss: 6.309\n",
      "[3, 3300] loss: 6.544\n",
      "[3, 3400] loss: 6.710\n",
      "[3, 3500] loss: 6.498\n",
      "[3, 3600] loss: 6.524\n",
      "[3, 3700] loss: 6.337\n",
      "[3, 3800] loss: 6.073\n",
      "[3, 3900] loss: 6.887\n",
      "[3, 4000] loss: 6.242\n",
      "[3, 4100] loss: 6.263\n",
      "[3, 4200] loss: 6.488\n",
      "[3, 4300] loss: 6.043\n",
      "[3, 4400] loss: 6.481\n",
      "[3, 4500] loss: 6.141\n",
      "[3, 4600] loss: 6.402\n",
      "[3, 4700] loss: 6.620\n",
      "[3, 4800] loss: 6.585\n",
      "[3, 4900] loss: 6.627\n",
      "[3, 5000] loss: 6.257\n",
      "[3, 5100] loss: 6.438\n",
      "[3, 5200] loss: 6.169\n",
      "[3, 5300] loss: 6.326\n",
      "[3, 5400] loss: 6.038\n",
      "[3, 5500] loss: 6.269\n",
      "[3, 5600] loss: 6.348\n",
      "[3, 5700] loss: 6.381\n",
      "[3, 5800] loss: 6.524\n",
      "[3, 5900] loss: 6.544\n",
      "[3, 6000] loss: 6.221\n",
      "[3, 6100] loss: 6.075\n",
      "[3, 6200] loss: 6.514\n",
      "[3, 6300] loss: 6.569\n",
      "[3, 6400] loss: 6.585\n",
      "[3, 6500] loss: 6.435\n",
      "[3, 6600] loss: 6.391\n",
      "[3, 6700] loss: 6.427\n",
      "[3, 6800] loss: 6.287\n",
      "[3, 6900] loss: 6.409\n",
      "[3, 7000] loss: 6.390\n",
      "[3, 7100] loss: 6.249\n",
      "[3, 7200] loss: 6.448\n",
      "[3, 7300] loss: 6.517\n",
      "[3, 7400] loss: 6.186\n",
      "[3, 7500] loss: 6.123\n",
      "[3, 7600] loss: 6.232\n",
      "[3, 7700] loss: 5.987\n",
      "[3, 7800] loss: 6.308\n",
      "[3, 7900] loss: 5.946\n",
      "[3, 8000] loss: 6.207\n",
      "[3, 8100] loss: 6.245\n",
      "[3, 8200] loss: 6.590\n",
      "[3, 8300] loss: 6.158\n",
      "[3, 8400] loss: 6.468\n",
      "[3, 8500] loss: 5.973\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# チャンネル次元を追加し、floatに変換\u001b[39;00m\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mf:\\deep-learning\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\deep-learning\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[1;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m7\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[1;32mf:\\deep-learning\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\deep-learning\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\deep-learning\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\deep-learning\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# データローダーの作成\n",
    "train_loader = torch.utils.data.DataLoader(ds['train'], batch_size=4, shuffle=True)\n",
    "\n",
    "# モデルの訓練\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data['image'], data['label']\n",
    "        inputs = inputs.squeeze(2).float()  # チャンネル次元を追加し、floatに変換\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # 100ミニバッチごとに平均損失を出力\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
